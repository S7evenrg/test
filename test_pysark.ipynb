{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "NusaTGuesJLV",
        "outputId": "5dc69ee8-e6ae-45f4-c35c-161b8d00588e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-a78ff754152b>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    df = spark.read.csv(\"file.csv\", header=True, sep=\";\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import col, concat_ws, lag\n",
        "\n",
        "# Initialize a Spark session\n",
        "spark = SparkSession.builder.appName(\"FlightTurns\").getOrCreate()\n",
        "\n",
        "# You can replace this with your actual DataFrame creation code\n",
        "df = spark.read.csv(\"file.csv\", header=True, sep=\";\")\n",
        "\n",
        "# Sort the DataFrame by aircraft registration code and departure timestamp\n",
        "sorted_df = df.orderBy(\"acft_regs_cde\", \"actl_dep_lcl_tms\")\n",
        "\n",
        "# Calculate the time difference between consecutive rows for the same aircraft\n",
        "window_spec = Window.partitionBy(\"acft_regs_cde\").orderBy(\"actl_dep_lcl_tms\")\n",
        "sorted_df = sorted_df.withColumn(\"time_diff\", col(\"actl_dep_lcl_tms\").cast(\"long\") - lag(\"actl_arr_lcl_tms\").over(window_spec))\n",
        "\n",
        "# Create a new column with a string of flights based on the turn of the aircraft\n",
        "sorted_df = sorted_df.withColumn(\"next_flights\", concat_ws(\", \", \"id\", \"orig\", \"dest\", \"actl_dep_lcl_tms\", \"actl_arr_lcl_tms\", \"flight_num\"))\n",
        "\n",
        "#task 1\n",
        "# Show the resulting DataFrame\n",
        "sorted_df.show(truncate=False)\n",
        "\n",
        "# Initialize a Spark session\n",
        "spark = SparkSession.builder.appName(\"AirportFlights\").getOrCreate()\n",
        "\n",
        "# You can replace this with your actual DataFrame creation code\n",
        " df = spark.read.csv(\"file.csv\", header=True, sep=\";\")\n",
        "\n",
        "# Define the time format\n",
        "time_format = \"yyyy-MM-dd'T'HH:mm:ss\"\n",
        "\n",
        "# Create a window specification for the time intervals\n",
        "window_spec = window(col(\"actl_dep_lcl_tms\"), \"2 hours\", \"15 minutes\")\n",
        "\n",
        "# Group the data by airport codes (origin and destination) and the time window\n",
        "airport_counts = df.groupBy(\"orig\", window_spec).count().orderBy(\"window\")\n",
        "\n",
        "#task 2\n",
        "# Show the resulting DataFrame\n",
        "airport_counts.show(truncate=False)\n",
        "\n",
        "# Stop the Spark session\n",
        "spark.stop()\n"
      ]
    }
  ]
}